{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shared_lib.utils' from 'shared_lib/utils.pyc'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, json, time, shutil\n",
    "import itertools, collections\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.1\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# Import model\n",
    "#import cnnlm\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'Data_Set/'\n",
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_DATA = os.path.join(PROJECT_PATH, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 20 newsgroup data as input to CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load 20 newsgroup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0\t = alt.atheism\n",
      "class: 1\t = comp.graphics\n",
      "class: 2\t = comp.os.ms-windows.misc\n",
      "class: 3\t = comp.sys.ibm.pc.hardware\n",
      "class: 4\t = comp.sys.mac.hardware\n",
      "class: 5\t = comp.windows.x\n",
      "class: 6\t = misc.forsale\n",
      "class: 7\t = rec.autos\n",
      "class: 8\t = rec.motorcycles\n",
      "class: 9\t = rec.sport.baseball\n",
      "class: 10\t = rec.sport.hockey\n",
      "class: 11\t = sci.crypt\n",
      "class: 12\t = sci.electronics\n",
      "class: 13\t = sci.med\n",
      "class: 14\t = sci.space\n",
      "class: 15\t = soc.religion.christian\n",
      "class: 16\t = talk.politics.guns\n",
      "class: 17\t = talk.politics.mideast\n",
      "class: 18\t = talk.politics.misc\n",
      "class: 19\t = talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Get newsgroup data\n",
    "newsgroup_data_all = fetch_20newsgroups(subset = 'all', remove=('headers', 'footers', 'quotes'))\n",
    "all_data, all_labels = newsgroup_data_all.data, newsgroup_data_all.target\n",
    "\n",
    "# List of all the class labels\n",
    "label_list = list(newsgroup_data_all.target_names)\n",
    "\n",
    "# Print the class labels\n",
    "i = 0\n",
    "for label in label_list:\n",
    "    print \"class: %i\\t = %s\" %(i, label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determine the length of document to use\n",
    "\n",
    "* From the distribution, must of the document is quite short. The original paper use **2000** word length which we can use this length or try other length if needed. \n",
    "\n",
    "* If a document is longer than the defined doc length, it will be cut, if it is shorter, it will be padded.\n",
    "\n",
    "* < PAD > tag is used for padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document length distribution of 20 newsgroup data\n",
    "\n",
    "* Does using 2000 document length makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 4536, Max Length: 158791, Min Length: 0, Avg Length: 1255.431\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt4AAAHwCAYAAACR2miEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABhA8AYAgAEEbwAAGOD/B0eDz+Zh1iZUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c4dad91d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_len =[]\n",
    "for doc in all_data:\n",
    "    doc_len.append(len(doc))\n",
    "\n",
    "# Document length statistics\n",
    "print \"Number of Samples: %i, Max Length: %i, Min Length: %i, Avg Length: %.3f\" \\\n",
    "    %(len(doc_len), max(doc_len), min(doc_len), np.mean(doc_len))\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(doc_len, 300)\n",
    "plt.title(\"Document Length Distribution\")\n",
    "plt.xlabel(\"Word Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Vocabulary using 20 newsgroup data set\n",
    "\n",
    "* Load all data from library => remove header/footer/quotes => clean string => create corpus => build vocabulary\n",
    "\n",
    "* To build corpus, we write to raw txt, then use NLTK to process the raw text to a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup_all.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "f = open('./Data_Set/newsgroup_prep/newsgroup_all.txt', 'w') \n",
    "for doc in all_data:\n",
    "    # Clean up str\n",
    "    doc = utils.clean_str((doc).encode('utf-8'))\n",
    "    # remove stop words and do stemming optionaly\n",
    "    doc = utils.preprocess_stop_stem(doc, stop=True, sent=True, stem=False)\n",
    "    f.write(\"%s\\n\" %(doc))\n",
    "f.close()\n",
    "\n",
    "# RegEx or list of file names\n",
    "data_20newsgroup = os.path.join(PROJECT_DATA, 'newsgroup_prep/')\n",
    "\n",
    "corpus = PlaintextCorpusReader(data_20newsgroup, 'newsgroup_all.txt')\n",
    "\n",
    "for infile in sorted(corpus.fileids()):\n",
    "    print infile # The fileids of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 20000 words\n"
     ]
    }
   ],
   "source": [
    "V = 20000\n",
    "vocab = vocabulary.Vocabulary((utils.canonicalize_word(w) \n",
    "                               for w in utils.flatten(corpus.sents())),\n",
    "                               size = V)\n",
    "print \"Vocabulary: %d words\" % vocab.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare Data for the CNN\n",
    "\n",
    "### Option 1. Train word Embedding with CNN. \n",
    "\n",
    "#### Tokenize document and build input data for word2vec\n",
    "\n",
    "* Load data => remove header/footer/quotes => cleaned string => cut and pad => use vocabulary to tokenize\n",
    "\n",
    "* Need to enable randomly select a number of classes for training and test data\n",
    "\n",
    "* Instead of using Sk-learn's building selection of train or test data. Build our own train/test data based on %split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Select Classes:  ['comp.sys.mac.hardware', 'talk.religion.misc', 'comp.os.ms-windows.misc', 'sci.space', 'comp.graphics']\n"
     ]
    }
   ],
   "source": [
    "# Select training and test data based on the number of classes\n",
    "# Including randomization option\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(8)\n",
    "\n",
    "num_class = 5\n",
    "randomize = True\n",
    "\n",
    "if randomize == True:\n",
    "    label_idxs = []\n",
    "    for x in range(num_class):\n",
    "        label_idxs.append(randint(0, 19))\n",
    "else:\n",
    "    label_idxs = range(num_class)\n",
    "\n",
    "select_classes = [label_list[i] for i in label_idxs]\n",
    "print \"Randomly Select Classes: \", select_classes\n",
    "\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                                    categories=select_classes)\n",
    "\n",
    "all_data, all_labels = newsgroups_all.data, newsgroups_all.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4536 docs (5.60058e+06 tokens)\n",
      "Training set: 3628 docs (4477827 tokens)\n",
      "Test set: 908 docs (1122749 tokens)\n"
     ]
    }
   ],
   "source": [
    "doc_length = 200\n",
    "\n",
    "# Preprocess data\n",
    "# Cleaning special characters\n",
    "# Cut or pad based on document length\n",
    "all_docs = utils.preprocess_doc(all_data, length = doc_length)\n",
    "\n",
    "train_docs, train_labels, test_docs, test_labels = utils.get_train_test_docs(all_docs, \n",
    "                                                                             all_labels, \n",
    "                                                                             split = 0.8, \n",
    "                                                                             shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Training Docs shape: (3628, 200) should equal to (batch_size, doc_length)\n",
      "Input Training labels shape: (3628, 5) should equal to (batch_size, num_class)\n",
      "Input Testing Docs shape: (908, 200) should equal to (batch_size, doc_length)\n",
      "Input Testing labels shape: (908, 5) should equal to (batch_size, num_class)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize documents and conver to ID\n",
    "# We tokenize each docs in the dataset and convert to vocab ID\n",
    "# matrix of batch_size x doc_length\n",
    "train_docs_ids = utils.docs_to_ids(train_docs, vocab)\n",
    "test_docs_ids = utils.docs_to_ids(test_docs, vocab)\n",
    "\n",
    "# Convert label to one-hot-code\n",
    "train_labels_oh = np.eye(num_class)[train_labels]\n",
    "test_labels_oh = np.eye(num_class)[test_labels]\n",
    "\n",
    "print \"Input Training Docs shape:\", train_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Training labels shape:\", train_labels_oh.shape, \"should equal to (batch_size, num_class)\"\n",
    "print \"Input Testing Docs shape:\", test_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Testing labels shape:\", test_labels_oh.shape, \"should equal to (batch_size, num_class)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 Load Google Pretrained Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_bin(fname, vocab):\n",
    "    \"\"\"\n",
    "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
    "    \"\"\"\n",
    "    word_vecs = {}\n",
    "    with open(fname, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())\n",
    "        print \"Google Word2vec Vocabulary Size:\", vocab_size\n",
    "        print \"Vector size:\", layer1_size\n",
    "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "        print \"Binary Length of word vector:\", binary_len\n",
    "        for line in xrange(vocab_size):\n",
    "            word = []\n",
    "            while True: # Read 1 char a time\n",
    "                ch = f.read(1) \n",
    "                if ch == ' ': # If it is a space, a word is read, we join then to read its vector\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n': # If it is not \\n, grouping character\n",
    "                    word.append(ch) \n",
    "            if word in vocab.wordset: # If a word in the 20 newsgroup vocab, get its vector\n",
    "                word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')  \n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    f.close()\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Word2vec Vocabulary Size: 3000000\n",
      "Vector size: 300\n",
      "Binary Length of word vector: 1200\n"
     ]
    }
   ],
   "source": [
    "google_word2vec = load_google_bin('./google_word2vec/GoogleNews-vectors-negative300.bin', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 16555\n",
      "--- Print a sample of google_word2vec vocabulary ---\n",
      "Word: raining \t\t Vector: [ 0.02331543  0.05004883 -0.00059891] ...\n",
      "Word: writings \t\t Vector: [ 0.18945312  0.2109375   0.20507812] ...\n",
      "Word: divinely \t\t Vector: [-0.02783203 -0.40820312 -0.01037598] ...\n",
      "Word: foul \t\t Vector: [ 0.18847656 -0.28710938  0.33007812] ...\n",
      "Word: four \t\t Vector: [ 0.0859375  -0.07275391  0.01672363] ...\n",
      "Word: gag \t\t Vector: [ 0.14648438 -0.08203125 -0.00897217] ...\n",
      "Word: prefix \t\t Vector: [ 0.34570312  0.1640625   0.11425781] ...\n",
      "Word: woods \t\t Vector: [ 0.11328125 -0.01165771 -0.20800781] ...\n",
      "Word: verses \t\t Vector: [ 0.28710938  0.15820312  0.23828125] ...\n",
      "Word: hanging \t\t Vector: [ 0.08984375  0.13769531 -0.14941406] ...\n",
      "Word: woody \t\t Vector: [ 0.08251953  0.44140625  0.07421875] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "print \"--- Print a sample of google_word2vec vocabulary ---\"\n",
    "i = 0\n",
    "for k, v in google_word2vec.iteritems():\n",
    "    if i <= 10:\n",
    "        print \"Word: %s \\t\\t Vector: %s ...\" %(k, v[:3])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross check vocabulary in 20newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = r'\\b([A-Za-z]+)\\b'\n",
    "count_w = []\n",
    "count_s = []\n",
    "for word in vocab.wordset:    \n",
    "    if re.search(regex, str(word)):\n",
    "        count_w.append(str(word))\n",
    "    else:\n",
    "        count_s.append(str(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of full letter words 18724\n",
      "Number of mixed ascii words 1276\n"
     ]
    }
   ],
   "source": [
    "print \"Number of full letter words\", len(count_w)\n",
    "print \"Number of mixed ascii words\", len(count_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u3', '51s', '51t', '2z', '9k']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_s[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take care of unknown words from 20newsgroup that does not exist in google word2vec\n",
    "\n",
    "* 0.25 is chosen so the unknown vectors have (approximately) same variance as pre-trained ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_unknown_words(google_word2vec, vocab, k=300):\n",
    "    for word in vocab.wordset:\n",
    "        if word not in google_word2vec:\n",
    "            google_word2vec[word] = np.random.uniform(-0.25,0.25,k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_unknown_words(google_word2vec, vocab, k=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 20000\n",
      "Pre-trained word2vec size (20000, 300)\n"
     ]
    }
   ],
   "source": [
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "pt_word2vec = np.array(google_word2vec.values())\n",
    "print \"Pre-trained word2vec size\", pt_word2vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Illustrated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cnn.png\" width = \"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOC Paper Terminology and Notes:\n",
    "\n",
    "* Embedding Layer:\n",
    "\n",
    "    * batch_size: N\n",
    "    * number of class: M\n",
    "    * A document matrix has size of $s \\times d$\n",
    "        * word embedding dimension: d => 300\n",
    "        * doc length: s => 2000\n",
    "    \n",
    "    \n",
    "* CNN Layer\n",
    "\n",
    "    * Region size: h => [3, 4, 5]\n",
    "    * Width of the filter: d => 300\n",
    "    * Number of filters per region: f => 150\n",
    "    * CNN out o: k => f x h = 150 x 3\n",
    "    \n",
    "\n",
    "* Output Layer\n",
    "    * W: $r \\times k$\n",
    "    * W': $M \\times r$\n",
    "    * y: $M$\n",
    "\n",
    "Note: The DOC Paper used a 2 fully connected output layer before softmax which is different from common approach\n",
    "\n",
    "$$out = W'(ReLU(Wo + b)) + b'$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN Paramters\n",
    "# doc_length = 100 => to be aligned with DOC paper?\n",
    "# num_class = 3 => to be adjusted based on stratified CV strategy from the DOC paper\n",
    "# vocab.size => If we don't use google word2vec, it will be vocab.size from newsgroup data alone\n",
    "# embedding_size => to be aligned with DOC paper\n",
    "# filter_size = [3, 4] => to be aligned with DOC paper\n",
    "# num_filters = 100 => to be aligned w\n",
    "\n",
    "doc_length = doc_length # s\n",
    "num_classes = num_class # M\n",
    "vocab_size = vocab.size\n",
    "embedding_size = 300 # d\n",
    "embedding_train = True # if True, we train word embedding, if not we use pretrained word2vec\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 150 # f\n",
    "l2_reg_lambda = 0.0\n",
    "dropout_prob = 0.5\n",
    "hidden = 250 # r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Placeholders for input, output and dropout\n",
    "# x_: Document, Size: (batch, document_length) word in indice\n",
    "# y_: Classes, Size: (batch, num_of_classes)\n",
    "# dropout_keep_prob: Dropout regularization parameter\n",
    "\n",
    "x_ = tf.placeholder(tf.int32, [None, doc_length], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes], name=\"y\")\n",
    "dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "# Keeping track of l2 regularization loss (optional)\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "# Embedding layer (Train embedding layer)\n",
    "# Need different implementation if use google pretrained word2vec\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "    # The vocab to vector table for lookup (to be trained or pre-trained)\n",
    "    if embedding_train:\n",
    "        C_ = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"C\")\n",
    "    else:\n",
    "        C_ = tf.placeholder(tf.float32, [vocab_size, embedding_size], name=\"C\")\n",
    "    \n",
    "    # Embedding output needs to be in size: (batch, doc_length, embedding_size, 1)\n",
    "    # Lookup gives (batch, doc_length, embedding_size)\n",
    "    # Therefore, we need to expand the dimension to 4D to work with conv2d\n",
    "    embedded_out = tf.expand_dims(tf.nn.embedding_lookup(C_, x_), -1)\n",
    "\n",
    "# Create a convolution + maxpool layer for each filter size\n",
    "pooled_outputs = []\n",
    "for i, filter_size in enumerate(filter_sizes):\n",
    "    with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "        \n",
    "        # Convolution Layer\n",
    "        # input shape: (batch, height(doc length, width(embedding size), channels(1) )\n",
    "        # filter shape: (filter_height, filter width(same as embedding size), in_channel, out_channels)\n",
    "        # in_channel = 1 for our data\n",
    "        # out_channel = num_filters\n",
    "        filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "        \n",
    "        # To experiment with normal distribution\n",
    "        W_ = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "        b_ = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "        \n",
    "        # \"VALID\" padding means no padding at edge\n",
    "        # Return shape (batch, height(doc length, width(embedding size), 1)\n",
    "        conv_ = tf.nn.conv2d(embedded_out, W_, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "        \n",
    "        # Apply nonlinearity using Relu (train fasster than tanh)\n",
    "        # Return shape (batch, height(doc length, 1, 1)\n",
    "        h_ = tf.nn.relu(tf.nn.bias_add(conv_, b_), name=\"relu\")\n",
    "        \n",
    "        # Maxpooling over the outputs\n",
    "        # ksize is window for pooling, we took 1 value for width direction\n",
    "        # For height, apply to each convolution steps to stripe the whole input matrix.\n",
    "        # Return shape (1, doc_length-filter_size+1, 1, 1)\n",
    "        pooled = tf.nn.max_pool(h_, \n",
    "                                ksize=[1, doc_length - filter_size + 1, 1, 1],\n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='VALID', \n",
    "                                name=\"pool\")\n",
    "        pooled_outputs.append(pooled)\n",
    "\n",
    "# Combine all the pooled features\n",
    "# find the total number of filters = num_of_filters * num_of_region\n",
    "# If we use [2, 3, 4] and 2 filter per region, we have 3 * 2 = 6 filters\n",
    "num_filters_total = num_filters * len(filter_sizes)\n",
    "\n",
    "# combine pooling output to feature vectors\n",
    "# h_pool_flat in shape of (batch_size, ? , num_filters_total)\n",
    "h_pool = tf.concat(pooled_outputs, 3)\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "\n",
    "# Add dropout\n",
    "with tf.name_scope(\"dropout\"):\n",
    "    h_drop = tf.nn.dropout(h_pool_flat, dropout_keep_prob)\n",
    "\n",
    "# Output Layer: Softmax\n",
    "# Final (unnormalized) scores and predictions\n",
    "# Do we need to normalize?\n",
    "with tf.name_scope(\"Output_layer\"):\n",
    "    Z1_ = tf.Variable(tf.random_uniform([num_filters_total, hidden], -1.0, 1.0), name = \"Z1\")\n",
    "    Z2_ = tf.Variable(tf.random_uniform([hidden, num_classes], -1.0, 1.0), name = \"Z2\")\n",
    "    b1_ = tf.Variable(tf.constant(0.1, shape=[hidden]), name=\"b1\")\n",
    "    b2_ = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b2\")\n",
    "    hidden_out = tf.nn.relu(tf.matmul(h_drop, Z1_) + b1_)\n",
    "    logits_ = tf.add(tf.matmul(hidden_out, Z2_), b2_, name=\"logits\")\n",
    "    \n",
    "    # L2 loss\n",
    "    l2_loss += tf.nn.l2_loss(Z1_)\n",
    "    l2_loss += tf.nn.l2_loss(b1_)\n",
    "    l2_loss += tf.nn.l2_loss(Z2_)\n",
    "    l2_loss += tf.nn.l2_loss(b2_)\n",
    "    \n",
    "    #scores = tf.nn.xw_plus_b(h_drop, W, b, name=\"scores\")\n",
    "    predictions_ = tf.argmax(logits_, 1, name=\"predictions\")\n",
    "\n",
    "# Calculate mean cross-entropy loss\n",
    "with tf.name_scope(\"cost_function\"):\n",
    "    per_example_losses_ = tf.nn.softmax_cross_entropy_with_logits(logits=logits_, \n",
    "                                                                 labels=y_,\n",
    "                                                                 name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_losses_) + l2_reg_lambda * l2_loss\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_predictions_ = tf.equal(predictions_, tf.argmax(y_, 1))\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_predictions_, \"float\"), name=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Train Word Embedding along with CNN **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_length: 200       \n",
      "num_classes: 5         \n",
      "vocabulary size: 20000     \n",
      "embedding size: 300       \n",
      "Train embedding?  True\n",
      "filter size: [3, 4, 5] \n",
      "number of filters: 150       \n",
      "L2 Regularization: 0.00      \n",
      "Drop out prob: 0.50      \n",
      "Hidden before output: 250       \n"
     ]
    }
   ],
   "source": [
    "print \"doc_length: {:<10d}\".format(doc_length) # s\n",
    "print \"num_classes: {:<10d}\".format(num_class) # M\n",
    "print \"vocabulary size: {:<10d}\".format(vocab.size)\n",
    "print \"embedding size: {:<10d}\".format(embedding_size) # d\n",
    "print \"Train embedding? \", embedding_train\n",
    "print \"filter size: {:<10s}\".format(filter_sizes)\n",
    "print \"number of filters: {:<10d}\".format(num_filters)\n",
    "print \"L2 Regularization: {:<10.2f}\".format(l2_reg_lambda)\n",
    "print \"Drop out prob: {:<10.2f}\".format(dropout_prob)\n",
    "print \"Hidden before output: {:<10d}\".format(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for training\n",
    "def train_batch(session, batch, alpha, train_embedding):\n",
    "    # Feed last column as targets\n",
    "    if train_embedding:\n",
    "        feed_dict = {x_:train_docs_ids,\n",
    "                     y_:train_labels_oh,\n",
    "                     dropout_keep_prob:dropout_prob, # No dropout\n",
    "                     alpha_:alpha}\n",
    "    else:\n",
    "        feed_dict = {x_:train_docs_ids,\n",
    "                     y_:train_labels_oh,\n",
    "                     C_:pt_word2vec, # use google word2vec\n",
    "                     dropout_keep_prob:dropout_prob, # No dropout\n",
    "                     alpha_:alpha}\n",
    "    c, a, pred, _ = session.run([loss_, accuracy_, predictions_, train_step_],\n",
    "                       feed_dict=feed_dict)\n",
    "    return c, a, pred\n",
    "\n",
    "def batch_generator(data, batch_size):\n",
    "    \"\"\"Generate minibatches from data.\"\"\"\n",
    "    for i in xrange(0, len(data), batch_size):\n",
    "        yield data[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Training\"):\n",
    "    alpha_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdagradOptimizer(alpha_)\n",
    "    #optimizer_ = tf.train.AdamOptimizer(alpha_)\n",
    "    train_step_ = optimizer_.minimize(loss_)\n",
    "    \n",
    "# Initializer step\n",
    "init_ = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[epoch 1] seen 0 minibatches\n",
      "[epoch 1] seen 10 minibatches\n",
      "[epoch 1] seen 20 minibatches\n",
      "[epoch 1] seen 30 minibatches\n",
      "[epoch 1] Completed 36 minibatches in 0:11:26\n",
      "[epoch 1] Average cost: 5918.996\n",
      "[epoch 1] Accuracy 0.249\n",
      "[epoch 1] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.11      0.15       773\n",
      "          1       0.44      0.20      0.28       774\n",
      "          2       0.21      0.08      0.11       784\n",
      "          3       0.23      0.71      0.35       794\n",
      "          4       0.20      0.08      0.11       503\n",
      "\n",
      "avg / total       0.27      0.25      0.21      3628\n",
      "\n",
      "\n",
      "[epoch 2] seen 0 minibatches\n",
      "[epoch 2] seen 10 minibatches\n",
      "[epoch 2] seen 20 minibatches\n",
      "[epoch 2] seen 30 minibatches\n",
      "[epoch 2] Completed 36 minibatches in 0:11:31\n",
      "[epoch 2] Average cost: 2.161\n",
      "[epoch 2] Accuracy 0.268\n",
      "[epoch 2] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.19      0.22       773\n",
      "          1       0.53      0.19      0.28       774\n",
      "          2       0.20      0.07      0.10       784\n",
      "          3       0.25      0.75      0.37       794\n",
      "          4       0.23      0.06      0.09       503\n",
      "\n",
      "avg / total       0.30      0.27      0.22      3628\n",
      "\n",
      "\n",
      "[epoch 3] seen 0 minibatches\n",
      "[epoch 3] seen 10 minibatches\n",
      "[epoch 3] seen 20 minibatches\n",
      "[epoch 3] seen 30 minibatches\n",
      "[epoch 3] Completed 36 minibatches in 0:11:26\n",
      "[epoch 3] Average cost: 1.827\n",
      "[epoch 3] Accuracy 0.260\n",
      "[epoch 3] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.12      0.17       773\n",
      "          1       0.80      0.16      0.27       774\n",
      "          2       0.25      0.15      0.18       784\n",
      "          3       0.23      0.75      0.35       794\n",
      "          4       0.21      0.03      0.06       503\n",
      "\n",
      "avg / total       0.37      0.26      0.22      3628\n",
      "\n",
      "\n",
      "[epoch 4] seen 0 minibatches\n",
      "[epoch 4] seen 10 minibatches\n",
      "[epoch 4] seen 20 minibatches\n",
      "[epoch 4] seen 30 minibatches\n",
      "[epoch 4] Completed 36 minibatches in 0:11:27\n",
      "[epoch 4] Average cost: 1.711\n",
      "[epoch 4] Accuracy 0.271\n",
      "[epoch 4] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.09      0.14       773\n",
      "          1       0.51      0.22      0.30       774\n",
      "          2       0.25      0.14      0.18       784\n",
      "          3       0.25      0.78      0.37       794\n",
      "          4       0.19      0.04      0.06       503\n",
      "\n",
      "avg / total       0.30      0.27      0.22      3628\n",
      "\n",
      "\n",
      "[epoch 5] seen 0 minibatches\n",
      "[epoch 5] seen 10 minibatches\n",
      "[epoch 5] seen 20 minibatches\n",
      "[epoch 5] seen 30 minibatches\n",
      "[epoch 5] Completed 36 minibatches in 0:11:28\n",
      "[epoch 5] Average cost: 1.662\n",
      "[epoch 5] Accuracy 0.268\n",
      "[epoch 5] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.14      0.19       773\n",
      "          1       0.75      0.17      0.28       774\n",
      "          2       0.22      0.13      0.16       784\n",
      "          3       0.24      0.77      0.37       794\n",
      "          4       0.22      0.04      0.06       503\n",
      "\n",
      "avg / total       0.35      0.27      0.22      3628\n",
      "\n",
      "\n",
      "[epoch 6] seen 0 minibatches\n",
      "[epoch 6] seen 10 minibatches\n",
      "[epoch 6] seen 20 minibatches\n",
      "[epoch 6] seen 30 minibatches\n",
      "[epoch 6] Completed 36 minibatches in 0:11:33\n",
      "[epoch 6] Average cost: 1.627\n",
      "[epoch 6] Accuracy 0.277\n",
      "[epoch 6] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.18      0.22       773\n",
      "          1       0.89      0.17      0.28       774\n",
      "          2       0.26      0.15      0.19       784\n",
      "          3       0.24      0.76      0.36       794\n",
      "          4       0.34      0.04      0.07       503\n",
      "\n",
      "avg / total       0.41      0.28      0.24      3628\n",
      "\n",
      "\n",
      "[epoch 7] seen 0 minibatches\n",
      "[epoch 7] seen 10 minibatches\n",
      "[epoch 7] seen 20 minibatches\n",
      "[epoch 7] seen 30 minibatches\n",
      "[epoch 7] Completed 36 minibatches in 0:11:30\n",
      "[epoch 7] Average cost: 1.603\n",
      "[epoch 7] Accuracy 0.273\n",
      "[epoch 7] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.14      0.19       773\n",
      "          1       0.82      0.18      0.30       774\n",
      "          2       0.24      0.15      0.18       784\n",
      "          3       0.24      0.76      0.37       794\n",
      "          4       0.35      0.04      0.07       503\n",
      "\n",
      "avg / total       0.39      0.27      0.23      3628\n",
      "\n",
      "\n",
      "[epoch 8] seen 0 minibatches\n",
      "[epoch 8] seen 10 minibatches\n",
      "[epoch 8] seen 20 minibatches\n",
      "[epoch 8] seen 30 minibatches\n",
      "[epoch 8] Completed 36 minibatches in 0:11:31\n",
      "[epoch 8] Average cost: 1.595\n",
      "[epoch 8] Accuracy 0.280\n",
      "[epoch 8] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.15      0.20       773\n",
      "          1       0.87      0.20      0.33       774\n",
      "          2       0.23      0.15      0.18       784\n",
      "          3       0.24      0.76      0.37       794\n",
      "          4       0.28      0.04      0.07       503\n",
      "\n",
      "avg / total       0.39      0.28      0.24      3628\n",
      "\n",
      "\n",
      "[epoch 9] seen 0 minibatches\n",
      "[epoch 9] seen 10 minibatches\n",
      "[epoch 9] seen 20 minibatches\n",
      "[epoch 9] seen 30 minibatches\n",
      "[epoch 9] Completed 36 minibatches in 0:11:24\n",
      "[epoch 9] Average cost: 1.585\n",
      "[epoch 9] Accuracy 0.277\n",
      "[epoch 9] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.17      0.22       773\n",
      "          1       0.87      0.19      0.31       774\n",
      "          2       0.21      0.12      0.15       784\n",
      "          3       0.24      0.77      0.37       794\n",
      "          4       0.38      0.04      0.07       503\n",
      "\n",
      "avg / total       0.40      0.28      0.24      3628\n",
      "\n",
      "\n",
      "[epoch 10] seen 0 minibatches\n",
      "[epoch 10] seen 10 minibatches\n",
      "[epoch 10] seen 20 minibatches\n",
      "[epoch 10] seen 30 minibatches\n",
      "[epoch 10] Completed 36 minibatches in 0:11:31\n",
      "[epoch 10] Average cost: 1.580\n",
      "[epoch 10] Accuracy 0.274\n",
      "[epoch 10] Classificaiton Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      0.16      0.21       773\n",
      "          1       0.89      0.17      0.29       774\n",
      "          2       0.23      0.14      0.17       784\n",
      "          3       0.24      0.77      0.37       794\n",
      "          4       0.38      0.03      0.06       503\n",
      "\n",
      "avg / total       0.41      0.27      0.23      3628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One epoch = one pass through the training data\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "alpha = 0.5  # learning rate\n",
    "min_alpha = 0.1\n",
    "alpha_delta = (alpha - min_alpha) / num_epochs\n",
    "print_every = 10\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(init_)\n",
    "\n",
    "t0 = time.time()\n",
    "for epoch in xrange(1,num_epochs+1):\n",
    "    t0_epoch = time.time()\n",
    "    epoch_cost = 0.0\n",
    "    total_batches = 0\n",
    "    print \"\"\n",
    "    for i, batch in enumerate(batch_generator(train_docs_ids, batch_size)):\n",
    "        if (i % print_every == 0):\n",
    "            print \"[epoch %d] seen %d minibatches\" % (epoch, i)\n",
    "        \n",
    "        cost, accuracy, pred = train_batch(session, batch, alpha, embedding_train)\n",
    "        epoch_cost += cost\n",
    "        total_batches = i + 1\n",
    "\n",
    "    avg_cost = epoch_cost / total_batches\n",
    "    alpha = alpha - alpha_delta\n",
    "    print \"[epoch %d] Completed %d minibatches in %s\" % (epoch, i, utils.pretty_timedelta(since=t0_epoch))\n",
    "    print \"[epoch %d] Average cost: %.03f\" % (epoch, avg_cost,)\n",
    "    print \"[epoch %d] Accuracy %.03f\" %(epoch, accuracy)\n",
    "    print \"[epoch %d] Classificaiton Report\\n\" %(epoch)\n",
    "    print classification_report(train_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation with Test Set with Trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.261\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.34      0.15      0.21       200\n",
      "          1       0.41      0.14      0.21       211\n",
      "          2       0.21      0.15      0.18       179\n",
      "          3       0.25      0.77      0.37       193\n",
      "          4       0.12      0.02      0.03       125\n",
      "\n",
      "avg / total       0.28      0.26      0.21       908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_batch(session):\n",
    "    feed_dict = {x_:test_docs_ids,\n",
    "                 y_:test_labels_oh,\n",
    "                 dropout_keep_prob:dropout_prob}\n",
    "    a, pred = session.run([accuracy_, predictions_], feed_dict=feed_dict)\n",
    "    return a, pred\n",
    "\n",
    "accuracy, pred = predict_batch(session)\n",
    "print \"Test Accuracy is %.03f\" %(accuracy)\n",
    "print classification_report(test_labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation with Test Set with Google Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is 0.211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.03      0.06       200\n",
      "          1       0.12      0.01      0.02       211\n",
      "          2       0.08      0.01      0.01       179\n",
      "          3       0.21      0.95      0.35       193\n",
      "          4       0.00      0.00      0.00       125\n",
      "\n",
      "avg / total       0.18      0.21      0.09       908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_batch(session):\n",
    "    feed_dict = {x_:test_docs_ids,\n",
    "                 y_:test_labels_oh,\n",
    "                 C_:pt_word2vec,\n",
    "                 dropout_keep_prob:dropout_prob}\n",
    "    a, pred = session.run([accuracy_, predictions_], feed_dict=feed_dict)\n",
    "    return a, pred\n",
    "\n",
    "accuracy, pred = predict_batch(session)\n",
    "print \"Test Accuracy is %.03f\" %(accuracy)\n",
    "print classification_report(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
